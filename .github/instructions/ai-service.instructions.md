## AI 服务开发规范

### 规则：Python 代码生成标准

- **Python 版本**: 必须使用 Python >= 3.10
- **框架选型**: 优先使用项目指定的 AI 框架 (LangChain/LlamaIndex/DSPy)
- **模型集成**:
  - **向量化**: **Qwen-Embedding-0.6B** - 核心向量化模型，负责文本到向量的转换
  - **LLM**: **Qwen2.5-7B-Instruct** - 核心大语言模型，负责基于上下文的答案生成
- **API 设计**: 提供 RESTful API 供 Go 服务调用
- **错误处理**: 统一的错误响应格式
- **日志记录**: 结构化日志输出

### 规则：Qwen 模型使用规范

- **Qwen-Embedding-0.6B 使用要求**:
  - 主要用于将用户查询和文档内容转换为向量表示
  - 确保输入文本长度不超过模型最大限制
  - 批量处理时注意性能优化和内存使用
- **Qwen2.5-7B-Instruct 使用要求**:
  - 专门用于基于检索上下文生成答案
  - 必须构建包含上下文的提示词模板
  - 控制生成参数（温度、最大长度等）以确保答案质量

### 规则：Go 与 Python 服务协作

- **接口约定**: 使用 JSON 进行数据交换
- **超时控制**: Go 调用 Python API 时必须设置合理的超时时间
- **熔断机制**: 实现断路器模式防止 AI 服务过载
- **重试策略**: 对临时失败的 AI 调用进行指数退避重试

### 规则：向量检索实现

- **向量化流程**: 用户查询 → Qwen-Embedding → 向量表示
- **相似度搜索**: 使用 Elasticsearch 的向量搜索能力
- **结果排序**: 基于相似度分数排序返回文档 ID
- **性能优化**: 批量处理和缓存机制

### 规则：答案生成实现

- **上下文组装**: 根据文档 ID 获取完整内容
- **提示词工程**: 构建包含上下文的提示词模板
- **模型调用**: 使用 Qwen2.5-7B-Instruct 生成答案
- **后处理**: 答案格式化和质量检查

### 规则：服务监控和运维

- **健康检查**: 提供 `/health` 接口用于服务状态检查
- **性能指标**: 监控响应时间、成功率、资源使用
- **日志规范**: 结构化日志包含请求 ID、处理时间等信息
- **错误追踪**: 详细的错误信息便于问题排查