## 核心设#### 模式一：同步旁路缓存 (应用层负责)

- **识别方法**:
  - 在 `internal/data` 的写入方法（如 `Update`、`Delete`）中，你会看到对 `gocache` 的 `Delete()` 或 `Invalidate()` 的显式调用。
  - `biz` 层的 `Repo` 接口定义中，写入方法可能会返回 `error`，暗示需要处理缓存操作的结果。

- **你的任务**:
  - **保持模式**: 当你修改这些方法时，必须维持 **"先写数据库，再删缓存"** 的顺序。
  - **原子性**: 数据库操作和缓存操作应被视为一个整体，尽管它们不是事务性的。确保在数据库写入成功后才执行缓存失效。
  - **参考实现**: 查看 `internal/data/user.go` (如果存在) 中的写入操作，那里会有该模式的典型实现。

#### 模式二：异步缓存失效 (CDC + Flink 负责)

- **识别方法**:
  - 在 `internal/data` 的写入方法中，**没有任何** `gocache.Delete()` 或 `Invalidate()` 调用
  - 代码注释中可能标注 `// Cache invalidation handled by CDC pipeline`
  - 存在独立的 Flink 作业代码（位于单独的代码仓库或目录）
  - 配置文件中有 Debezium 和 Flink 的连接配置

- **你的任务**:
  - **严禁添加缓存逻辑**: 在应用代码中**绝对不能**添加任何缓存失效代码
  - **只关注数据库**: 写入方法只需确保数据库操作的正确性和事务完整性
  - **信任 CDC 管道**: 缓存失效由 Debezium 捕获数据变更 → Kafka 传输 → Flink 处理 → Memcached 失效，完全自动化
  - **注释规范**: 在写入方法上添加注释说明缓存由 CDC 管道处理，避免后续维护者误添加缓存代码

- **工作流程**:
  1. **应用写入**: `internal/data` 执行数据库 `INSERT/UPDATE/DELETE` 操作
  2. **CDC 捕获**: Debezium 监控 PostgreSQL WAL 日志，捕获变更事件
  3. **消息发布**: 变更事件发布到 Kafka Topic（如 `dbserver1.public.users`）
  4. **流式处理**: Flink 作业消费 Kafka 消息，解析出需要失效的缓存键
  5. **缓存失效**: Flink 调用 Memcached 删除接口，完成缓存失效

- **优势与代价**:
  - ✅ **优势**: 应用代码更纯粹，缓存与业务逻辑解耦，支持跨服务缓存一致性
  - ⚠️ **代价**: 缓存失效有延迟（通常 < 1 秒），需要额外的基础设施（Debezium + Flink）

#### 模式三：RAG 数据流架构 (Go 微服务 + Python AI 服务)则：识别并应用正确的缓存模式

本项目的核心是探索两种缓存策略。在修改代码，特别是 `internal/data` 层时，你必须首先识别当前代码属于哪种模式，并严格遵守该模式的规则。

#### 模式一：同步旁路缓存 (应用层负责)

- **识别方法**:
  - 在 `internal/data` 的写入方法（如 `Update`、`Delete`）中，你会看到对 `gocache` 的 `Delete()` 或 `Invalidate()` 的显式调用。
  - `biz` 层的 `Repo` 接口定义中，写入方法可能会返回 `error`，暗示需要处理缓存操作的结果。

- **你的任务**:
  - **保持模式**: 当你修改这些方法时，必须维持 **“先写数据库，再删缓存”** 的顺序。
  - **原子性**: 数据库操作和缓存操作应被视为一个整体，尽管它们不是事务性的。确保在数据库写入成功后才执行缓存失效。
  - **参考实现**: 查看 `internal/data/user.go` (如果存在) 中的写入操作，那里会有该模式的典型实现。

#### 模式三：RAG 数据流架构 (Go 微服务 + Python AI 服务)

- **识别方法**:
  - 涉及 Kafka 消息队列、Flink 流处理、Elasticsearch 向量搜索的代码
  - Go 服务调用 Python AI 服务的 HTTP 接口
  - 包含向量化处理和索引写入逻辑

- **你的任务**:
  - **数据写入职责**: Go 微服务负责消费富化数据、向量化处理和 Elasticsearch 索引写入
  - **数据读取职责**: Go 服务调用 Python AI 服务进行向量检索和答案生成
  - **协作模式**: 明确 Go/Python 服务边界，Go 负责数据管道，Python 负责 AI 计算
  - **错误处理**: 实现熔断、重试和超时控制机制
