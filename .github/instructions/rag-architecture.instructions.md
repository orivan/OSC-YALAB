## RAG 数据流架构模式

### 规则：理解并实现完整的 RAG 数据管道

RAG (Retrieval-Augmented Generation) 架构是系统的核心，包含完整的数据写入和读取流程。

#### 数据写入流程（Go 微服务负责）
1. **数据捕获**: Debezium 监控 PostgreSQL WAL 日志，捕获数据变更事件
2. **数据富化**: Flink 作业消费原始数据，进行业务逻辑处理和数据增强
3. **富化数据发布**: 处理后的数据写回 Kafka 新 Topic（如 `topic_rich_data`）
4. **向量处理**: Go 微服务集群订阅富化数据 Topic，调用向量化模型 (Qwen-Embedding) 将文本转换为向量
5. **索引写入**: 将向量化的数据写入 Elasticsearch，建立可搜索的索引

#### 数据读取流程（Go + Python 协作）
1. **用户查询**: Kratos 服务接收查询请求
2. **向量检索**: Go 服务调用 Python AI 服务接口，传递用户问题进行向量化搜索
3. **上下文组装**: Go 服务根据返回的文档 ID 从缓存/数据库获取完整内容
4. **答案生成**: Go 服务再次调用 Python AI 服务，传递问题和上下文生成答案
5. **返回结果**: Go 服务将最终答案返回给用户

#### 职责边界
- **Go (Kratos) 服务**:
  - 数据管道处理和流式消费
  - 向量化和索引写入 Elasticsearch
  - 业务流程编排和高可用控制
  - 缓存管理和数据访问

- **Python AI 服务**:
  - 向量检索和相似度搜索
  - 大语言模型调用和答案生成
  - 提示词工程和模型管理

#### 代码生成规则
- **Go 微服务**: 负责 Kafka 消费者、向量化模型调用、Elasticsearch 客户端操作
- **Python 服务**: 提供 REST API 接口供 Go 服务调用，内部处理向量搜索和 LLM 生成
- **错误处理**: 统一的错误响应格式，包含重试和熔断机制
- **监控**: 关键指标监控（延迟、成功率、资源使用）

#### 技术实现要点
- **Kafka Topics**: 区分原始数据 Topic 和富化数据 Topic
- **向量化**: 使用 **Qwen-Embedding-0.6B** 模型进行文本向量化
- **索引策略**: Elasticsearch 索引设计支持向量搜索和全文检索
- **答案生成**: 使用 **Qwen2.5-7B-Instruct** 大语言模型基于上下文生成答案
- **性能优化**: 批量处理、连接池、异步处理

---

### 规则：异常场景处理策略

#### Elasticsearch 异常处理

**场景 1: Elasticsearch 索引写入失败**
- **检测**: 监控索引写入的错误率和延迟
- **策略**: 
  - 将失败的文档记录到重试队列（使用 Redis 或本地持久化队列）
  - 异步重试，最多重试 5 次，指数退避
  - 超过重试次数后记录到死信队列，触发人工介入告警
  - **不影响 Kafka 消费进度**：确保 Kafka offset 正常提交

**示例处理流程**:
```go
func (s *indexService) IndexDocument(ctx context.Context, doc *Document) error {
    err := s.esClient.Index(ctx, doc)
    if err != nil {
        // 记录到重试队列
        s.retryQueue.Add(doc)
        s.log.Warnw("ES index failed, added to retry queue", 
            "doc_id", doc.ID, "error", err)
        // 不返回错误，避免阻塞 Kafka 消费
        return nil
    }
    return nil
}
```

**场景 2: Elasticsearch 查询失败**
- **检测**: 查询超时（> 5 秒）或连接错误
- **降级策略**:
  1. **优先级 1**: 从缓存中返回最近的搜索结果（如果查询相似）
  2. **优先级 2**: 降级到 PostgreSQL 全文搜索（使用 `tsvector` 或 `LIKE`）
  3. **优先级 3**: 返回固定的默认文档列表（热门文档）
- **恢复**: 每 30 秒探测 Elasticsearch 可用性，恢复后切回正常流程

**场景 3: 索引不存在或映射错误**
- **首次启动**: 自动创建索引并设置正确的映射（mapping）
- **映射冲突**: 记录错误，阻止写入，触发告警（需要人工修复索引）

---

#### Python AI 服务异常处理

**场景 1: 向量检索服务不可用**
- **超时配置**: 3 秒超时
- **重试策略**: 最多重试 2 次，间隔 100ms
- **降级策略**:
  1. 降级到关键词匹配（使用 Elasticsearch 的 `match` 查询）
  2. 如果 Elasticsearch 也不可用，返回最近访问的热门文档
- **用户体验**: 在响应中标注 `"mode": "degraded"` 告知降级状态

**场景 2: LLM 生成服务超时或失败**
- **超时配置**: 10 秒超时
- **重试策略**: 不重试（生成时间长，重试代价高）
- **降级策略**:
  1. 返回检索到的原始文档片段（前 3 个最相关文档的摘要）
  2. 添加说明："AI 生成服务暂时不可用，以下是相关文档内容"
- **缓存结果**: 对于相同问题，缓存成功的生成结果（TTL 1 小时）

**场景 3: Python 服务返回业务错误**
- **400 错误（输入无效）**: 直接返回给用户，提示修正输入
- **422 错误（无结果）**: 返回空结果或推荐默认内容
- **500 错误（内部错误）**: 触发降级策略

**示例降级实现**:
```go
func (s *aiService) GenerateAnswer(ctx context.Context, query string, context []string) (string, error) {
    ctx, cancel := context.WithTimeout(ctx, 10*time.Second)
    defer cancel()
    
    resp, err := s.client.Generate(ctx, query, context)
    if err != nil {
        s.log.Warnw("LLM generation failed, degrading", "error", err)
        
        // 降级：返回文档摘要
        summary := s.buildDocumentSummary(context)
        return fmt.Sprintf("[降级模式] 相关文档内容：\n%s", summary), nil
    }
    
    return resp.Answer, nil
}
```

---

#### Kafka 消息处理异常

**场景 1: Kafka 消费延迟过高**
- **检测**: 监控消费 Lag（积压消息数）
- **策略**:
  - Lag > 10,000: 触发告警
  - Lag > 50,000: 自动扩展消费者实例数（Kubernetes HPA）
  - Lag > 100,000: 考虑临时提高批处理大小，降低索引质量要求

**场景 2: 消息格式错误或解析失败**
- **策略**:
  - 记录错误消息到死信队列（DLQ）
  - 继续消费下一条消息，不阻塞整个流程
  - 定期分析 DLQ 中的消息，修复上游数据问题

**场景 3: Flink 作业失败**
- **检测**: 监控 Flink 作业的 CheckPoint 状态
- **策略**:
  - 自动重启失败的 Flink 作业（从最近的 CheckPoint 恢复）
  - 如果连续失败 > 3 次，触发告警，暂停作业
  - 人工修复数据问题后，从指定 offset 重新消费

---

#### 向量化模型异常

**场景 1: Qwen-Embedding 模型加载失败**
- **启动阶段**: 容器启动时预加载模型，失败则阻止服务启动（快速失败）
- **运行时**: 如果模型文件损坏，记录错误并触发告警，使用备用模型（如果配置）

**场景 2: 向量化处理超时**
- **超时配置**: 单个文档向量化超时 5 秒
- **策略**:
  - 跳过该文档的向量化，仅索引文本内容（支持关键词搜索）
  - 记录到重试队列，异步重试
  - 如果文档过长（> 10,000 字），自动截断或分段处理

**场景 3: 批量处理部分失败**
- **策略**:
  - 采用"尽力而为"模式，成功的继续索引，失败的记录重试
  - 不因部分失败回滚整个批次
  - 监控成功率，低于 95% 触发告警

---

#### 数据一致性保障

**场景 1: Elasticsearch 索引延迟**
- **正常延迟**: < 5 秒（从数据库写入到可搜索）
- **检测**: 通过时间戳对比检测延迟
- **影响**: 用户可能短期内搜索不到刚创建的内容
- **缓解**: 在创建成功响应中返回文档 ID，前端可直接访问（绕过搜索）

**场景 2: Kafka 消息丢失**
- **保障机制**:
  - Kafka 配置 `acks=all` 确保消息持久化
  - Debezium 使用 `at-least-once` 语义
  - 定期对账：PostgreSQL 与 Elasticsearch 的数据一致性检查
- **修复**: 发现不一致时，触发全量或增量重建索引

**场景 3: 向量与文档内容不一致**
- **触发条件**: 文档更新后，向量未及时更新
- **检测**: 在文档中存储 `vector_version` 字段，与 `content_version` 对比
- **修复**: 定期扫描不一致记录，重新向量化

---

### 规则：监控与告警指标

#### 数据管道健康度

| 指标 | 正常阈值 | 告警阈值 | 严重阈值 |
|------|---------|---------|---------|
| **Kafka 消费 Lag** | < 1,000 | > 10,000 | > 50,000 |
| **ES 索引延迟** | < 5s | > 30s | > 60s |
| **向量化成功率** | > 99% | < 95% | < 90% |
| **ES 写入成功率** | > 99% | < 95% | < 90% |

#### AI 服务健康度

| 指标 | 正常阈值 | 告警阈值 | 严重阈值 |
|------|---------|---------|---------|
| **向量检索延迟 P99** | < 500ms | > 2s | > 5s |
| **LLM 生成延迟 P99** | < 5s | > 10s | > 20s |
| **降级率** | < 0.1% | > 1% | > 5% |
| **错误率** | < 0.1% | > 1% | > 5% |

#### 端到端查询链路

| 指标 | 正常阈值 | 告警阈值 |
|------|---------|---------|
| **总延迟 P99** | < 10s | > 20s |
| **成功率** | > 99.5% | < 99% |
| **降级响应占比** | < 1% | > 5% |